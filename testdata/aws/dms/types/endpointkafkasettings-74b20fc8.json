{
    "properties": {
        "broker": {
            "type": "string",
            "description": "Kafka broker location. Specify in the form broker-hostname-or-ip:port.\n"
        },
        "includeControlDetails": {
            "type": "boolean",
            "description": "Shows detailed control information for table definition, column definition, and table and column changes in the Kafka message output. Default is `false`.\n"
        },
        "includeNullAndEmpty": {
            "type": "boolean",
            "description": "Include NULL and empty columns for records migrated to the endpoint. Default is `false`.\n"
        },
        "includePartitionValue": {
            "type": "boolean",
            "description": "Shows the partition value within the Kafka message output unless the partition type is `schema-table-type`. Default is `false`.\n"
        },
        "includeTableAlterOperations": {
            "type": "boolean",
            "description": "Includes any data definition language (DDL) operations that change the table in the control data, such as `rename-table`, `drop-table`, `add-column`, `drop-column`, and `rename-column`. Default is `false`.\n"
        },
        "includeTransactionDetails": {
            "type": "boolean",
            "description": "Provides detailed transaction information from the source database. This information includes a commit timestamp, a log position, and values for `transaction_id`, previous `transaction_id`, and `transaction_record_id` (the record offset within a transaction). Default is `false`.\n"
        },
        "messageFormat": {
            "type": "string",
            "description": "Output format for the records created on the endpoint. Message format is `JSON` (default) or `JSON_UNFORMATTED` (a single line with no tab).\n"
        },
        "messageMaxBytes": {
            "type": "integer",
            "description": "Maximum size in bytes for records created on the endpoint Default is `1,000,000`.\n"
        },
        "noHexPrefix": {
            "type": "boolean",
            "description": "Set this optional parameter to true to avoid adding a '0x' prefix to raw data in hexadecimal format. For example, by default, AWS DMS adds a '0x' prefix to the LOB column type in hexadecimal format moving from an Oracle source to a Kafka target. Use the `no_hex_prefix` endpoint setting to enable migration of RAW data type columns without adding the `'0x'` prefix.\n"
        },
        "partitionIncludeSchemaTable": {
            "type": "boolean",
            "description": "Prefixes schema and table names to partition values, when the partition type is `primary-key-type`. Doing this increases data distribution among Kafka partitions. For example, suppose that a SysBench schema has thousands of tables and each table has only limited range for a primary key. In this case, the same primary key is sent from thousands of tables to the same partition, which causes throttling. Default is `false`.\n"
        },
        "saslPassword": {
            "type": "string",
            "description": "Secure password you created when you first set up your MSK cluster to validate a client identity and make an encrypted connection between server and client using SASL-SSL authentication.\n",
            "secret": true
        },
        "saslUsername": {
            "type": "string",
            "description": "Secure user name you created when you first set up your MSK cluster to validate a client identity and make an encrypted connection between server and client using SASL-SSL authentication.\n"
        },
        "securityProtocol": {
            "type": "string",
            "description": "Set secure connection to a Kafka target endpoint using Transport Layer Security (TLS). Options include `ssl-encryption`, `ssl-authentication`, and `sasl-ssl`. `sasl-ssl` requires `sasl_username` and `sasl_password`.\n"
        },
        "sslCaCertificateArn": {
            "type": "string",
            "description": "ARN for the private certificate authority (CA) cert that AWS DMS uses to securely connect to your Kafka target endpoint.\n"
        },
        "sslClientCertificateArn": {
            "type": "string",
            "description": "ARN of the client certificate used to securely connect to a Kafka target endpoint.\n"
        },
        "sslClientKeyArn": {
            "type": "string",
            "description": "ARN for the client private key used to securely connect to a Kafka target endpoint.\n"
        },
        "sslClientKeyPassword": {
            "type": "string",
            "description": "Password for the client private key used to securely connect to a Kafka target endpoint.\n",
            "secret": true
        },
        "topic": {
            "type": "string",
            "description": "Kafka topic for migration. Default is `kafka-default-topic`.\n"
        }
    },
    "type": "object",
    "required": [
        "broker"
    ]
}